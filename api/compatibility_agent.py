import math
import os
import statistics
from dataclasses import dataclass, field, asdict
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

from openai import OpenAI
from dotenv import load_dotenv

from metrics.emotion_sync_advanced import AdvancedEmotionSynchronyCalculator
from metrics.semantic_alignment_advanced import AdvancedSemanticAlignmentCalculator
from metrics.empathy_composite import EmpathyCompositeCalculator

# =============================
# æ•°æ®æ¨¡å‹
# =============================

@dataclass
class TranscriptTurn:
    speaker: str  # "therapist" / "patient"
    text: str
    start: float
    end: float


@dataclass
class EmotionPoint:
    speaker: str  # "therapist" / "patient"
    timestamp: float
    valence: float  # -1 ~ 1
    arousal: float  # 0 ~ 1


@dataclass
class CBTIndicators:
    techniques_used: List[str] = field(default_factory=list)
    technique_quality: float = 0.0


@dataclass
class HomeworkQuality:
    completion_rate: float = 0.0
    discussion_depth: float = 0.0


@dataclass
class SessionInput:
    session_id: str
    patient_id: str
    therapist_id: str
    session_date: str
    transcript: List[Dict[str, Any]]
    emotion_timeline: List[Dict[str, Any]]
    cbt_indicators: Dict[str, Any] = field(default_factory=dict)
    homework_quality: Dict[str, Any] = field(default_factory=dict)


@dataclass
class MetricWithTrend:
    current: float
    trend: str
    change_rate: Optional[str]
    label: str
    historical_avg: Optional[float]
    historical_values: List[float]


@dataclass
class TherapistReport:
    session_id: str
    metrics_summary: Dict[str, MetricWithTrend]
    clinical_interpretation: Dict[str, Any]
    alerts: List[Dict[str, Any]]


@dataclass
class PatientFamilyReport:
    summary: str
    key_points: List[str]
    progress: str


@dataclass
class ArchiveData:
    session_id: str
    patient_id: str
    therapist_id: str
    session_date: str
    raw_metrics: Dict[str, float]
    computed_fields: Dict[str, Any]


@dataclass
class CompatibilityOutput:
    therapist_report: TherapistReport
    patient_family_report: PatientFamilyReport
    archive_data: ArchiveData
    alerts: List[Dict[str, Any]]


# =============================
# å·¥å…·å‡½æ•°
# =============================


def _safe_pearson(xs: List[float], ys: List[float]) -> Optional[float]:
    """ç®€å•å®ç° Pearson ç›¸å…³ï¼Œé¿å…é¢å¤–ä¾èµ–ã€‚"""
    if len(xs) != len(ys) or len(xs) < 2:
        return None
    if len(set(xs)) == 1 or len(set(ys)) == 1:
        return None
    mean_x = statistics.mean(xs)
    mean_y = statistics.mean(ys)
    num = sum((x - mean_x) * (y - mean_y) for x, y in zip(xs, ys))
    den_x = math.sqrt(sum((x - mean_x) ** 2 for x in xs))
    den_y = math.sqrt(sum((y - mean_y) ** 2 for y in ys))
    if den_x == 0 or den_y == 0:
        return None
    return num / (den_x * den_y)


def _jaccard_similarity(a: List[str], b: List[str]) -> float:
    sa = set(w for w in a if w)
    sb = set(w for w in b if w)
    if not sa or not sb:
        return 0.0
    inter = len(sa & sb)
    union = len(sa | sb)
    return inter / union if union > 0 else 0.0


# =============================
# ä¸» Agent
# =============================


class CompatibilityMetricsAgent:
    """å¥‘åˆåº¦æŒ‡æ ‡è®¡ç®— Agentï¼ˆç®€åŒ–å®ç°ç‰ˆæœ¬ï¼‰ã€‚

    ç›®æ ‡ï¼š
    - æ¥æ”¶å•æ¬¡ä¼šè¯çš„ç»¼åˆæ•°æ®ï¼ˆè½¬å†™ã€æƒ…ç»ªæ—¶é—´çº¿ã€CBT æŒ‡æ ‡ç­‰ï¼‰
    - è®¡ç®— 5 ä¸ªæ ¸å¿ƒå¥‘åˆåº¦æŒ‡æ ‡
    - å’Œå†å²æ•°æ®ï¼ˆå½“å‰å†…å­˜ç‰ˆï¼‰åšç®€å•è¶‹åŠ¿åˆ†æ
    - ç”Ÿæˆï¼š
      - æ²»ç–—å¸ˆä¸“ä¸šæŠ¥å‘Š
      - æ‚£è€…/å®¶å±æ˜“æ‡‚æŠ¥å‘Š
      - å½’æ¡£ JSON æ•°æ®
    """

    def __init__(self) -> None:
        # æç®€â€œå†å²æ•°æ®åº“â€ï¼šä»…å­˜åœ¨å†…å­˜é‡Œï¼ŒæŒ‰ patient_id è®°å½•å†å²æŒ‡æ ‡
        self._history: Dict[str, List[Dict[str, float]]] = {}

        # é«˜çº§åˆ†æå™¨ï¼ˆæƒ…ç»ªåŒæ­¥ã€è¯­ä¹‰å¥‘åˆã€å…±æƒ…ç»¼åˆï¼‰
        self._emotion_advanced = AdvancedEmotionSynchronyCalculator()
        self._semantic_client: Optional[OpenAI] = None
        self._semantic_advanced: Optional[AdvancedSemanticAlignmentCalculator] = None
        self._empathy_composite = EmpathyCompositeCalculator()

        # æœ€è¿‘ä¸€æ¬¡ä¼šè¯çš„è¯¦ç»†åˆ†æç»“æœç¼“å­˜ï¼ˆç”¨äºæŠ¥å‘Š/å½’æ¡£ï¼‰
        self._last_emotion_detail: Optional[Dict[str, Any]] = None
        self._last_semantic_detail: Optional[Dict[str, Any]] = None
        self._last_empathy_composite: Optional[Dict[str, Any]] = None

    def set_semantic_client(self, client: OpenAI) -> None:
        """ç”±å¤–éƒ¨æ³¨å…¥ OpenRouter/OpenAI å®¢æˆ·ç«¯ï¼Œç”¨äºé«˜çº§è¯­ä¹‰å¥‘åˆåˆ†æã€‚"""
        self._semantic_client = client
        self._semantic_advanced = AdvancedSemanticAlignmentCalculator(client)

    # ======= å¯¹å¤–ä¸»å…¥å£ =======

    def analyze_session(self, session_data: Dict[str, Any]) -> CompatibilityOutput:
        session = SessionInput(**session_data)

        # 1. è®¡ç®— 5 ä¸ªæŒ‡æ ‡ï¼ˆå½“å‰å€¼ï¼‰
        metrics = self._compute_current_metrics(session)

        # 1.5 è®¡ç®—æƒ…ç»ª+è¯­ä¹‰çš„å…±æƒ…ç»¼åˆè¯„åˆ†ï¼ˆå¦‚æœæœ‰é«˜çº§ç»“æœï¼‰
        self._last_empathy_composite = None
        if self._last_emotion_detail is not None and self._last_semantic_detail is not None:
            try:
                self._last_empathy_composite = self._empathy_composite.calculate(
                    emotion_sync_data=self._last_emotion_detail,
                    semantic_alignment_data=self._last_semantic_detail,
                    linguistic_mirroring_data={"overall_score": metrics.get("linguistic_mirroring", 0.0)},
                )
            except Exception:
                self._last_empathy_composite = None

        # 2. åŠ è½½å†å²å¹¶åšè¶‹åŠ¿åˆ†æ
        trends = self._analyze_trends(session.patient_id, metrics)

        # 3. å‘Šè­¦æ£€æŸ¥
        alerts = self._check_alerts(session.patient_id, session.therapist_id, trends)

        # 4. ç»„è£…æŠ¥å‘Š
        therapist_report = self._build_therapist_report(
            session, trends, alerts, self._last_empathy_composite
        )
        patient_report = self._build_patient_report(session, trends)
        archive_data = self._build_archive_data(
            session, metrics, trends, self._last_empathy_composite
        )

        # 5. å†™å…¥â€œå†å²â€ï¼ˆå†…å­˜ç‰ˆï¼‰
        self._append_history(session.patient_id, metrics)

        return CompatibilityOutput(
            therapist_report=therapist_report,
            patient_family_report=patient_report,
            archive_data=archive_data,
            alerts=alerts,
        )

    # ======= æŒ‡æ ‡è®¡ç®— =======

    def _compute_current_metrics(self, session: SessionInput) -> Dict[str, float]:
        transcript = [TranscriptTurn(**t) for t in session.transcript]
        emotions = [EmotionPoint(**e) for e in session.emotion_timeline]

        emotion_sync = self._metric_emotion_synchrony(emotions)
        linguistic_mirroring = self._metric_linguistic_mirroring(transcript)
        semantic_alignment = self._metric_semantic_alignment(transcript)
        talk_ratio = self._metric_talk_ratio(transcript)
        response_latency = self._metric_response_latency(transcript)

        return {
            "emotion_synchrony": emotion_sync,
            "linguistic_mirroring": linguistic_mirroring,
            "semantic_alignment": semantic_alignment,
            "talk_ratio": talk_ratio,
            "response_latency": response_latency,
        }

    def _metric_emotion_synchrony(self, emotions: List[EmotionPoint]) -> float:
        """æƒ…ç»ªåŒæ­¥æŒ‡æ•°ï¼šä¼˜å…ˆä½¿ç”¨é«˜çº§åˆ†æå™¨ï¼Œå¤±è´¥æ—¶å›é€€åˆ°ç®€åŒ–ç‰ˆã€‚"""
        if not emotions:
            self._last_emotion_detail = None
            return 0.0

        # ä½¿ç”¨é«˜çº§åˆ†æå™¨
        try:
            timeline = [
                {
                    "speaker": e.speaker,
                    "timestamp": e.timestamp,
                    "valence": e.valence,
                    "arousal": e.arousal,
                }
                for e in emotions
            ]
            detail = self._emotion_advanced.calculate(timeline)
            self._last_emotion_detail = detail
            corr = float(detail.get("instant_sync", {}).get("correlation", 0.0))
            # æŠŠ [-1,1] æ˜ å°„åˆ° [0,1]
            return round((corr + 1.0) / 2.0, 3)
        except Exception:  # noqa: BLE001
            # å›é€€åˆ°åŸæ¥çš„ç®€åŒ– Pearson ç‰ˆæœ¬
            emotions_sorted = sorted(emotions, key=lambda e: e.timestamp)
            max_ts = max(e.timestamp for e in emotions_sorted)
            if max_ts <= 0:
                return 0.0
            bins = list(range(int(math.floor(max_ts)) + 1))
            therapist_vals: List[float] = []
            patient_vals: List[float] = []
            for i in bins:
                t_in_bin = [e.valence for e in emotions_sorted if e.speaker == "therapist" and i <= e.timestamp < i + 1]
                p_in_bin = [e.valence for e in emotions_sorted if e.speaker == "patient" and i <= e.timestamp < i + 1]
                therapist_vals.append(statistics.mean(t_in_bin) if t_in_bin else 0.0)
                patient_vals.append(statistics.mean(p_in_bin) if p_in_bin else 0.0)
            r = _safe_pearson(therapist_vals, patient_vals)
            if r is None:
                return 0.0
            return round((r + 1.0) / 2.0, 3)

    def _metric_linguistic_mirroring(self, transcript: List[TranscriptTurn]) -> float:
        """è¯­è¨€é•œåƒç‡ï¼ˆç®€åŒ–ç‰ˆï¼šè¯æ±‡ Jaccard + è¯­ä¹‰è¿‘ä¼¼ç¼ºçœï¼‰ã€‚"""
        patient_words: List[str] = []
        therapist_words: List[str] = []
        for t in transcript:
            words = t.text.replace("\n", " ").split()
            if t.speaker == "patient":
                patient_words.extend(words)
            elif t.speaker == "therapist":
                therapist_words.extend(words)
        lexical = _jaccard_similarity(patient_words, therapist_words)
        # æš‚æ—  embeddingï¼Œè¯­ä¹‰é•œåƒè¿‘ä¼¼ä¸ºè¯æ±‡é•œåƒ
        semantic = lexical
        overall = 0.3 * lexical + 0.7 * semantic
        return round(overall, 3)

    def _metric_semantic_alignment(self, transcript: List[TranscriptTurn]) -> float:
        """è¯­ä¹‰å¥‘åˆåº¦ï¼šä¼˜å…ˆä½¿ç”¨é«˜çº§è¯­ä¹‰æ¨¡å—ï¼Œå¤±è´¥æ—¶å›é€€åˆ°ç®€åŒ–ç‰ˆã€‚"""
        # å¦‚å·²é…ç½®é«˜çº§è¯­ä¹‰åˆ†æå™¨ï¼Œåˆ™è°ƒç”¨ LLM æ¨¡å—
        if self._semantic_advanced is not None:
            try:
                transcript_dicts = [
                    {
                        "speaker": t.speaker,
                        "text": t.text,
                        "start": t.start,
                        "end": t.end,
                    }
                    for t in transcript
                ]
                detail = self._semantic_advanced.calculate(transcript_dicts)
                self._last_semantic_detail = detail
                overall = float(detail.get("overall_alignment", 0.0))
                return round(overall, 3)
            except Exception:  # noqa: BLE001
                # å¦‚æœé«˜çº§åˆ†æå¤±è´¥ï¼Œç»§ç»­èµ°ç®€åŒ–é€»è¾‘
                self._last_semantic_detail = None

        # ç®€åŒ–å¯å‘å¼ç‰ˆæœ¬ï¼špatientâ†’therapist é‚»æ¥è½®æ¬¡ Jaccard
        pairs: List[Tuple[str, str]] = []
        for i in range(len(transcript) - 1):
            a, b = transcript[i], transcript[i + 1]
            if a.speaker == "patient" and b.speaker == "therapist":
                pairs.append((a.text, b.text))
        if not pairs:
            return 0.0
        scores: List[float] = []
        for p_text, t_text in pairs:
            p_words = p_text.replace("\n", " ").split()
            t_words = t_text.replace("\n", " ").split()
            s = _jaccard_similarity(p_words, t_words)
            scores.append(s)
        return round(statistics.mean(scores), 3) if scores else 0.0

    def _metric_talk_ratio(self, transcript: List[TranscriptTurn]) -> float:
        """è°ˆè¯æ¯”ä¾‹ï¼šè¿”å›æ²»ç–—å¸ˆè¯´è¯å æ¯”ï¼ˆ0~1ï¼‰ã€‚"""
        if not transcript:
            return 0.0
        therapist_secs = 0.0
        patient_secs = 0.0
        for t in transcript:
            dur = max(0.0, t.end - t.start)
            if t.speaker == "therapist":
                therapist_secs += dur
            elif t.speaker == "patient":
                patient_secs += dur
        total = therapist_secs + patient_secs
        if total <= 0:
            return 0.0
        return round(therapist_secs / total, 3)

    def _metric_response_latency(self, transcript: List[TranscriptTurn]) -> float:
        """å“åº”æ½œä¼æ—¶é—´ï¼šå¹³å‡è½®æ¢æ—¶çš„é—´éš”ï¼ˆç§’ï¼‰ã€‚"""
        if len(transcript) < 2:
            return 0.0
        gaps: List[float] = []
        for i in range(len(transcript) - 1):
            cur = transcript[i]
            nxt = transcript[i + 1]
            if cur.speaker != nxt.speaker:
                gap = nxt.start - cur.end
                if gap >= 0:
                    gaps.append(gap)
        if not gaps:
            return 0.0
        return round(statistics.mean(gaps), 3)

    # ======= å†å²ä¸è¶‹åŠ¿ =======

    def _append_history(self, patient_id: str, metrics: Dict[str, float]) -> None:
        self._history.setdefault(patient_id, []).append(metrics)

    def _analyze_trends(self, patient_id: str, metrics: Dict[str, float]) -> Dict[str, MetricWithTrend]:
        history = self._history.get(patient_id, [])
        trends: Dict[str, MetricWithTrend] = {}
        for name, current in metrics.items():
            hist_values = [h[name] for h in history if name in h]
            if not hist_values:
                trends[name] = MetricWithTrend(
                    current=current,
                    trend="åŸºçº¿",
                    change_rate=None,
                    label=self._label_metric(name, current, trend=None),
                    historical_avg=None,
                    historical_values=[],
                )
                continue
            last = hist_values[-1]
            if math.isclose(last, 0.0):
                change_rate = None
            else:
                change_rate_val = (current - last) / last * 100
                change_rate = f"{change_rate_val:+.1f}%"
            if current > last:
                t = "ä¸Šå‡"
            elif current < last:
                t = "ä¸‹é™"
            else:
                t = "æŒå¹³"
            avg = statistics.mean(hist_values)
            label = self._label_metric(name, current, trend=t)
            trends[name] = MetricWithTrend(
                current=current,
                trend=t,
                change_rate=change_rate,
                label=label,
                historical_avg=avg,
                historical_values=hist_values + [current],
            )
        return trends

    def _label_metric(self, name: str, value: float, trend: Optional[str]) -> str:
        """æ ¹æ®å½“å‰å€¼ + è¶‹åŠ¿ç”Ÿæˆç®€å•æ ‡ç­¾ã€‚"""
        base = ""
        if name in {"emotion_synchrony", "linguistic_mirroring", "semantic_alignment"}:
            if value >= 0.7:
                base = "ğŸŸ¢ ä¼˜ç§€"
            elif value >= 0.4:
                base = "ğŸ”µ è‰¯å¥½"
            elif value >= 0.2:
                base = "ğŸŸ¡ éœ€å…³æ³¨"
            else:
                base = "ğŸ”´ è­¦æˆ’"
        elif name == "talk_ratio":
            # æ²»ç–—å¸ˆ 30%~60% è§†ä¸ºç†æƒ³
            if 0.3 <= value <= 0.6:
                base = "ğŸŸ¢ å¹³è¡¡"
            elif 0.2 <= value <= 0.7:
                base = "ğŸ”µ å¯æ¥å—"
            else:
                base = "ğŸŸ¡ å¤±è¡¡"
        elif name == "response_latency":
            if value < 0.5:
                base = "ğŸŸ¡ è¿‡å¿«"
            elif value < 2.5:
                base = "ğŸŸ¢ è‡ªç„¶"
            else:
                base = "ğŸŸ¡ åæ…¢"
        if trend in {"ä¸Šå‡", "ä¸‹é™"}:
            arrow = "â¬†ï¸" if trend == "ä¸Šå‡" else "â¬‡ï¸"
            return f"{base} {arrow}"
        return base

    # ======= å‘Šè­¦ =======

    def _check_alerts(self, patient_id: str, therapist_id: str, trends: Dict[str, MetricWithTrend]) -> List[Dict[str, Any]]:
        alerts: List[Dict[str, Any]] = []
        # è§„åˆ™ç¤ºä¾‹ 1ï¼šè¯­ä¹‰å¥‘åˆåº¦è¿ç»­ä½ï¼ˆè¿™é‡Œç®€å•çœ‹å½“å‰å€¼ï¼‰
        sem = trends.get("semantic_alignment")
        if sem and sem.current < 0.4:
            alerts.append({
                "type": "semantic_alignment_low",
                "severity": "medium",
                "message": f"æœ¬æ¬¡è¯­ä¹‰å¥‘åˆåº¦åä½ï¼ˆ{sem.current:.2f}ï¼‰ï¼Œå»ºè®®åœ¨ä¸‹æ¬¡ä¼šè¯ä¸­æ›´å¤šå›´ç»•æ‚£è€…æ ¸å¿ƒå…³åˆ‡å±•å¼€ã€‚",
                "patient_id": patient_id,
                "therapist_id": therapist_id,
            })
        # è§„åˆ™ç¤ºä¾‹ 2ï¼šæƒ…ç»ªåŒæ­¥æ€¥å‰§ä¸‹é™
        emo = trends.get("emotion_synchrony")
        if emo and emo.change_rate is not None and emo.trend == "ä¸‹é™":
            try:
                rate = float(emo.change_rate.replace("%", ""))
                if rate <= -30.0:
                    alerts.append({
                        "type": "emotion_synchrony_drop",
                        "severity": "medium",
                        "message": f"æƒ…ç»ªåŒæ­¥æŒ‡æ•°è¾ƒä¸Šæ¬¡ä¸‹é™ {rate:.1f}%ï¼Œå¯èƒ½å­˜åœ¨å…±æƒ…æ–­è£‚ã€‚",
                        "patient_id": patient_id,
                        "therapist_id": therapist_id,
                    })
            except Exception:
                pass
        # è§„åˆ™ç¤ºä¾‹ 3ï¼šè°ˆè¯æ¯”ä¾‹å¤±è¡¡
        talk = trends.get("talk_ratio")
        if talk and (talk.current < 0.2 or talk.current > 0.7):
            alerts.append({
                "type": "talk_ratio_imbalanced",
                "severity": "low",
                "message": f"æœ¬æ¬¡æ²»ç–—å¸ˆè¯´è¯å æ¯”ä¸º {talk.current:.2f}ï¼Œå»ºè®®å…³æ³¨æ‚£è€…è¡¨è¾¾ç©ºé—´ã€‚",
                "patient_id": patient_id,
                "therapist_id": therapist_id,
            })
        return alerts

    # ======= æŠ¥å‘Šæ„å»º =======

    def _build_therapist_report(
        self,
        session: SessionInput,
        trends: Dict[str, MetricWithTrend],
        alerts: List[Dict[str, Any]],
        empathy_composite: Optional[Dict[str, Any]],
    ) -> TherapistReport:
        # é LLM ç‰ˆæœ¬çš„éå¸¸ç®€æ´â€œä¸´åºŠè§£è¯»â€
        overall_comment = "æ€»ä½“æ²Ÿé€šè´¨é‡ï¼š"  # å ä½ç®€å•è§„åˆ™
        sem = trends.get("semantic_alignment")
        emo = trends.get("emotion_synchrony")
        talk = trends.get("talk_ratio")
        if sem and emo:
            if sem.current >= 0.6 and emo.current >= 0.6:
                overall_comment += "è‰¯å¥½ï¼ˆæ‚£è€…è¾ƒæ˜“æ„Ÿåˆ°è¢«ç†è§£ï¼‰ã€‚"
            elif sem.current < 0.4:
                overall_comment += "éœ€å…³æ³¨è¯­ä¹‰å¥‘åˆåº¦ï¼Œé¿å…ç­”éæ‰€é—®ã€‚"
            else:
                overall_comment += "ä¸­ç­‰ï¼Œå¯åœ¨ä¸‹æ¬¡ä¼šè¯ä¸­è¿›ä¸€æ­¥åŠ å¼ºå›´ç»•æ ¸å¿ƒä¸»é¢˜çš„æ¢ç´¢ã€‚"
        key_findings: List[str] = []
        if sem:
            key_findings.append(f"è¯­ä¹‰å¥‘åˆåº¦ä¸º {sem.current:.2f}ï¼Œæ ‡ç­¾ï¼š{sem.label}ã€‚")
        if emo:
            key_findings.append(f"æƒ…ç»ªåŒæ­¥æŒ‡æ•°ä¸º {emo.current:.2f}ï¼Œæ ‡ç­¾ï¼š{emo.label}ã€‚")
        if talk:
            key_findings.append(f"æ²»ç–—å¸ˆè¯´è¯å æ¯”ä¸º {talk.current:.2f}ã€‚")
        # å¦‚å·²è®¡ç®—å…±æƒ…ç»¼åˆè¯„åˆ†ï¼Œåœ¨æŠ¥å‘Šä¸­åŠ å…¥ä¸€æ¡æ‘˜è¦
        if empathy_composite is not None:
            score = empathy_composite.get("empathy_composite_score")
            grade = empathy_composite.get("grade")
            if score is not None and grade is not None:
                key_findings.append(
                    f"å…±æƒ…ç»¼åˆè¯„åˆ†ä¸º {score:.1f}ï¼ˆç­‰çº§ï¼š{grade}ï¼‰ã€‚"
                )
        clinical_interpretation = {
            "overall_rating": overall_comment,
            "key_findings": key_findings,
            "recommendations": [
                "å¯é€‚å½“å¢åŠ å¼€æ”¾å¼æé—®ï¼Œé¼“åŠ±æ‚£è€…æ‰©å±•è‡ªå·±çš„å™è¿°ã€‚",
                "å›é¡¾æ‚£è€…å¤šæ¬¡æåˆ°çš„å…³é”®ä¿¡å¿µæˆ–ä¸»é¢˜ï¼Œé¿å…é¢‘ç¹è½¬ç§»è¯é¢˜ã€‚",
            ],
        }
        return TherapistReport(
            session_id=session.session_id,
            metrics_summary=trends,
            clinical_interpretation=clinical_interpretation,
            alerts=alerts,
        )

    def _build_patient_report(
        self,
        session: SessionInput,
        trends: Dict[str, MetricWithTrend],
    ) -> PatientFamilyReport:
        """ç»™æ‚£è€…/å®¶å±çœ‹çš„æ˜“æ‡‚ç‰ˆæœ¬ï¼ˆå½“å‰ä¸ºé LLM ç®€åŒ–ç‰ˆï¼‰ã€‚"""
        sem = trends.get("semantic_alignment")
        emo = trends.get("emotion_synchrony")
        talk = trends.get("talk_ratio")
        summary_parts: List[str] = []
        if emo and emo.current >= 0.6:
            summary_parts.append("æœ¬æ¬¡å’¨è¯¢ä¸­ï¼ŒåŒ»ç”Ÿæ•´ä½“ä¸Šæ¯”è¾ƒèƒ½å’Œä½ çš„æƒ…ç»ªåŒé¢‘ã€‚")
        if sem and sem.current >= 0.5:
            summary_parts.append("åŒ»ç”Ÿçš„å›åº”å¤§å¤šå›´ç»•ä½ çœŸæ­£å…³å¿ƒçš„é—®é¢˜å±•å¼€ã€‚")
        if not summary_parts:
            summary_parts.append("æœ¬æ¬¡å’¨è¯¢æ•´ä½“æ²Ÿé€šè´¨é‡å°šå¯ï¼Œåç»­è¿˜å¯ä»¥ç»§ç»­è°ƒæ•´å’Œä¼˜åŒ–ã€‚")
        progress = "è¿™æ˜¯ç³»ç»Ÿç»™å‡ºçš„è‡ªåŠ¨åˆ†æç»“æœï¼Œä»…ä¾›ä½ å’ŒåŒ»ç”Ÿå‚è€ƒï¼Œä¸ä»£è¡¨æ­£å¼è¯Šæ–­ã€‚"
        key_points: List[str] = []
        if talk:
            if 0.3 <= talk.current <= 0.6:
                key_points.append("ä½ å’ŒåŒ»ç”Ÿçš„è¯´è¯æ—¶é—´æ¯”è¾ƒå¹³è¡¡ã€‚")
            else:
                key_points.append("å¯ä»¥åœ¨å’¨è¯¢ä¸­å¤šè¡¨è¾¾è‡ªå·±çš„æƒ³æ³•å’Œæ„Ÿå—ã€‚")
        return PatientFamilyReport(
            summary="".join(summary_parts),
            key_points=key_points,
            progress=progress,
        )

    def _build_archive_data(
        self,
        session: SessionInput,
        metrics: Dict[str, float],
        trends: Dict[str, MetricWithTrend],
        empathy_composite: Optional[Dict[str, Any]],
    ) -> ArchiveData:
        """æ„å»ºç»“æ„åŒ–å½’æ¡£æ•°æ®ã€‚"""
        overall_score = statistics.mean(metrics.values()) if metrics else 0.0
        computed_fields = {
            "overall_compatibility_score": round(overall_score * 10, 2),  # ç²—ç•¥æ˜ å°„åˆ° 0-10
            "risk_level": "low",  # ç®€åŒ–ï¼šæš‚æ—¶ä¸ç»†åˆ†
        }
        if empathy_composite is not None:
            computed_fields["empathy_composite_score"] = empathy_composite.get(
                "empathy_composite_score"
            )
            computed_fields["empathy_grade"] = empathy_composite.get("grade")
        return ArchiveData(
            session_id=session.session_id,
            patient_id=session.patient_id,
            therapist_id=session.therapist_id,
            session_date=session.session_date,
            raw_metrics=metrics,
            computed_fields=computed_fields,
        )


# ä¾¿äºç›´æ¥æœ¬åœ°ç®€å•æµ‹è¯•
if __name__ == "__main__":
    # å°è¯•ä» .env åŠ è½½ OPENROUTER_API_KEYï¼Œç”¨äºé«˜çº§è¯­ä¹‰åˆ†æ
    load_dotenv()
    api_key = os.getenv("OPENROUTER_API_KEY")

    agent = CompatibilityMetricsAgent()

    if api_key:
        try:
            semantic_client = OpenAI(
                base_url="https://openrouter.ai/api/v1",
                api_key=api_key,
            )
            agent.set_semantic_client(semantic_client)
            print("âœ… å·²ä¸ºå¥‘åˆåº¦ Agent é…ç½® OpenRouter è¯­ä¹‰åˆ†æå®¢æˆ·ç«¯")
        except Exception as e:  # noqa: BLE001
            print(f"âš ï¸ é…ç½® OpenRouter è¯­ä¹‰åˆ†æå®¢æˆ·ç«¯å¤±è´¥ï¼Œå°†ä½¿ç”¨ç®€åŒ–è¯­ä¹‰æŒ‡æ ‡: {e}")
    else:
        print("âš ï¸ æœªæ‰¾åˆ° OPENROUTER_API_KEYï¼Œé«˜çº§è¯­ä¹‰å¥‘åˆåº¦åˆ†æå°†è¢«è·³è¿‡ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬ã€‚")

    dummy_session = {
        "session_id": "session_001",
        "patient_id": "patient_001",
        "therapist_id": "therapist_001",
        "session_date": datetime.now().isoformat(),
        "transcript": [
            {"speaker": "therapist", "text": "ä½ å¥½ï¼Œæœ€è¿‘æ„Ÿè§‰æ€ä¹ˆæ ·ï¼Ÿ", "start": 0.0, "end": 2.5},
            {"speaker": "patient", "text": "æœ€è¿‘å‹åŠ›æŒºå¤§çš„ï¼Œæ€»è§‰å¾—è‡ªå·±åšå¾—ä¸å¤Ÿå¥½ã€‚", "start": 3.0, "end": 8.0},
            {"speaker": "therapist", "text": "å¬èµ·æ¥ä½ å¯¹è‡ªå·±çš„è¦æ±‚å¾ˆé«˜ã€‚", "start": 8.5, "end": 11.0},
            {"speaker": "patient", "text": "æ˜¯çš„ï¼Œæ€»è§‰å¾—å¦‚æœåšä¸å¥½å°±å®Œè›‹äº†ã€‚", "start": 11.5, "end": 15.0},
        ],
        "emotion_timeline": [
            {"speaker": "patient", "timestamp": 1.0, "valence": -0.2, "arousal": 0.6},
            {"speaker": "therapist", "timestamp": 1.0, "valence": 0.1, "arousal": 0.4},
            {"speaker": "patient", "timestamp": 4.0, "valence": -0.4, "arousal": 0.7},
            {"speaker": "therapist", "timestamp": 5.0, "valence": -0.1, "arousal": 0.5},
            {"speaker": "patient", "timestamp": 12.0, "valence": -0.5, "arousal": 0.7},
            {"speaker": "therapist", "timestamp": 13.0, "valence": -0.2, "arousal": 0.5},
        ],
        "cbt_indicators": {"techniques_used": ["è‹æ ¼æ‹‰åº•æé—®"], "technique_quality": 0.7},
        "homework_quality": {"completion_rate": 0.8, "discussion_depth": 0.6},
    }

    out = agent.analyze_session(dummy_session)
    print("===== æ²»ç–—å¸ˆæŠ¥å‘Š =====")
    print(out.therapist_report.clinical_interpretation)
    print("\n===== æ‚£è€…/å®¶å±æŠ¥å‘Š =====")
    print(asdict(out.patient_family_report))
    print("\n===== å½’æ¡£æ•°æ® =====")
    print(asdict(out.archive_data))
